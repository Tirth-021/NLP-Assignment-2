{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Preprocessing HASOC CSVs (from .) ---\n",
      "  Processing ./english_2021.csv...\n",
      "    Wrote 1342 benign samples to temp_jsonl_data/hasoc_EN_benign.jsonl\n",
      "    Wrote 2501 toxic samples to temp_jsonl_data/hasoc_EN_toxic.jsonl\n",
      "  Processing ./hindi_2021.csv...\n",
      "    Wrote 3161 benign samples to temp_jsonl_data/hasoc_HI_benign.jsonl\n",
      "    Wrote 1433 toxic samples to temp_jsonl_data/hasoc_HI_toxic.jsonl\n",
      "Preprocessing complete.\n",
      "\n",
      "--- 2. Loading Model and Tokenizer ---\n",
      "Tokenizer loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10908e2dcd8f47a58b13fe6c3f2ea8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n",
      "\n",
      "\n",
      "--- 4. Starting 4-Way Collection & Analysis Loop ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "HASOC_FOLDER = \".\"\n",
    "TEMP_DATA_FOLDER = \"temp_jsonl_data\"\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "my_token = \"HFtoken\"\n",
    "\n",
    "batch_size = 64\n",
    "max_length = 400\n",
    "\n",
    "TOP_N_NEURONS = 100\n",
    "RESULTS_FILE = \"neuron_analysis_results_4WAY.json\"\n",
    "\n",
    "print(f\"--- 1. Preprocessing HASOC CSVs (from {HASOC_FOLDER}) ---\")\n",
    "os.makedirs(TEMP_DATA_FOLDER, exist_ok=True)\n",
    "\n",
    "csv_files_to_process = {\n",
    "    \"EN\": os.path.join(HASOC_FOLDER, \"english_2021.csv\"),\n",
    "    \"HI\": os.path.join(HASOC_FOLDER, \"hindi_2021.csv\")\n",
    "}\n",
    "job_file_map = {}\n",
    "\n",
    "for lang, filepath in csv_files_to_process.items():\n",
    "    print(f\"  Processing {filepath}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        benign_texts = df[df['task_1'] == 'NOT']['text'].tolist()\n",
    "        benign_outfile = os.path.join(TEMP_DATA_FOLDER, f\"hasoc_{lang}_benign.jsonl\")\n",
    "        job_file_map[f\"benign_{lang}\"] = (benign_outfile, \"BenignCompletion\")\n",
    "        with open(benign_outfile, 'w', encoding='utf-8') as f:\n",
    "            for text in benign_texts:\n",
    "                json.dump({\"BenignCompletion\": text}, f)\n",
    "                f.write('\\n')\n",
    "        print(f\"    Wrote {len(benign_texts)} benign samples to {benign_outfile}\")\n",
    "\n",
    "        toxic_texts = df[df['task_1'] == 'HOF']['text'].tolist()\n",
    "        toxic_outfile = os.path.join(TEMP_DATA_FOLDER, f\"hasoc_{lang}_toxic.jsonl\")\n",
    "        job_file_map[f\"toxic_{lang}\"] = (toxic_outfile, \"Completion\")\n",
    "        with open(toxic_outfile, 'w', encoding='utf-8') as f:\n",
    "            for text in toxic_texts:\n",
    "                json.dump({\"Completion\": text}, f)\n",
    "                f.write('\\n')\n",
    "        print(f\"    Wrote {len(toxic_texts)} toxic samples to {toxic_outfile}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    An error occurred processing {filepath}: {e}\")\n",
    "\n",
    "print(\"Preprocessing complete.\\n\")\n",
    "\n",
    "print(\"--- 2. Loading Model and Tokenizer ---\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=my_token)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"Tokenizer loaded.\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, dtype=torch.bfloat16, device_map=\"auto\", token=my_token\n",
    ")\n",
    "model.eval()\n",
    "print(\"Model and tokenizer loaded successfully.\\n\")\n",
    "\n",
    "def get_hook(storage_dict, layer_name):\n",
    "    def hook_fn(module, input, output):\n",
    "        storage_dict[layer_name].append(output.detach().cpu())\n",
    "    return hook_fn\n",
    "\n",
    "def run_activation_collection(input_filename, data_field, layer_names):\n",
    "    all_prompts = []\n",
    "    try:\n",
    "        with open(input_filename, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                all_prompts.append(data[data_field])\n",
    "        print(f\"    Loaded {len(all_prompts)} prompts.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Error loading {input_filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "    activation_storage = {}\n",
    "    hook_handles = []\n",
    "    for layer_name in layer_names:\n",
    "        activation_storage[layer_name] = []\n",
    "    \n",
    "    for i, layer in enumerate(model.model.layers):\n",
    "        if i >= len(layer_names): break\n",
    "        handle = layer.mlp.register_forward_hook(\n",
    "            get_hook(activation_storage, layer_names[i])\n",
    "        )\n",
    "        hook_handles.append(handle)\n",
    "\n",
    "    all_collected_activations = {name: [] for name in layer_names}\n",
    "    num_batches = math.ceil(len(all_prompts) / batch_size)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(all_prompts), batch_size), desc=\"      Processing\", ncols=100, leave=False):\n",
    "            for layer_name in activation_storage:\n",
    "                activation_storage[layer_name].clear()\n",
    "            \n",
    "            batch_prompts = all_prompts[i:i+batch_size]\n",
    "            \n",
    "            inputs = tokenizer(\n",
    "                batch_prompts,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=max_length\n",
    "            ).to(\"cuda\")\n",
    "            \n",
    "            model(**inputs)\n",
    "            last_token_indices = (inputs[\"attention_mask\"].sum(dim=1) - 1).cpu()\n",
    "\n",
    "            for layer_name, batch_activations_list in activation_storage.items():\n",
    "                full_batch_tensor = batch_activations_list[0]\n",
    "                last_token_activations = full_batch_tensor[\n",
    "                    torch.arange(full_batch_tensor.size(0)),\n",
    "                    last_token_indices\n",
    "                ] \n",
    "                all_collected_activations[layer_name].append(last_token_activations)\n",
    "    \n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    \n",
    "    final_activations = {}\n",
    "    for layer_name, tensor_list in all_collected_activations.items():\n",
    "        if tensor_list:\n",
    "            final_activations[layer_name] = torch.cat(tensor_list, dim=0)\n",
    "            \n",
    "    del all_prompts, all_collected_activations, activation_storage, hook_handles\n",
    "    gc.collect()\n",
    "    \n",
    "    return final_activations\n",
    "\n",
    "def analyze_differences(base_acts, diff_acts, layer_names):\n",
    "    layer_results = {}\n",
    "    for layer_name in layer_names:\n",
    "        base_tensor = base_acts[layer_name]\n",
    "        diff_tensor = diff_acts[layer_name]\n",
    "        \n",
    "        mean_base = base_tensor.mean(dim=0)\n",
    "        mean_diff = diff_tensor.mean(dim=0)\n",
    "        \n",
    "        mean_diff_values = mean_diff - mean_base\n",
    "        \n",
    "        top_values, top_indices = torch.topk(mean_diff_values, TOP_N_NEURONS)\n",
    "        \n",
    "        layer_results[layer_name] = {\n",
    "            \"top_neuron_indices\": top_indices.cpu().numpy().tolist(),\n",
    "            \"top_neuron_mean_diffs\": top_values.cpu().float().numpy().tolist()\n",
    "        }\n",
    "    return layer_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  --- Comparison 1: English Toxicity (Toxic EN vs Benign EN) ---\n",
      "    Running Benign EN collection...\n",
      "    Loaded 1342 prompts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Running Toxic EN collection...\n",
      "    Loaded 2501 prompts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4. Starting 4-Way Collection & Analysis Loop ---\")\n",
    "\n",
    "layer_names = [f\"model.model.layers.{i}.mlp\" for i in range(len(model.model.layers))]\n",
    "final_analysis_results = {}\n",
    "benign_activations_en = None\n",
    "benign_activations_hi = None\n",
    "\n",
    "print(\"\\n  --- Comparison 1: English Toxicity (Toxic EN vs Benign EN) ---\")\n",
    "print(\"    Running Benign EN collection...\")\n",
    "benign_file_en, benign_field_en = job_file_map[\"benign_EN\"]\n",
    "benign_activations_en = run_activation_collection(benign_file_en, benign_field_en, layer_names)\n",
    "\n",
    "print(\"    Running Toxic EN collection...\")\n",
    "toxic_file_en, toxic_field_en = job_file_map[\"toxic_EN\"]\n",
    "toxic_activations_en = run_activation_collection(toxic_file_en, toxic_field_en, layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Analyzing (Toxic EN - Benign EN)...\n",
      "    Analysis complete. Cleaning toxic activations from memory.\n",
      "\n",
      "  --- Comparison 2: Hindi Toxicity (Toxic HI vs Benign HI) ---\n",
      "    Running Benign HI collection...\n",
      "    Loaded 3161 prompts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      Processing:   0%|                                                      | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Running Toxic HI collection...\n",
      "    Loaded 1433 prompts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Analyzing (Toxic HI - Benign HI)...\n",
      "    Analysis complete. Cleaning toxic activations from memory.\n",
      "\n",
      "  --- Comparison 3 & 4: Language (Benign EN vs Benign HI) ---\n",
      "    Analyzing (Benign EN - Benign HI)...\n",
      "    Analyzing (Benign HI - Benign EN)...\n",
      "    Language analysis complete.\n",
      "    Cleaning up all remaining activations.\n",
      "\n",
      "--- 5. All processing complete. Saving final results. ---\n",
      "Successfully saved 4-way analysis results to 'neuron_analysis_results_4WAY.json'.\n",
      "\n",
      "--- All Done ---\n"
     ]
    }
   ],
   "source": [
    "if benign_activations_en and toxic_activations_en:\n",
    "    print(\"    Analyzing (Toxic EN - Benign EN)...\")\n",
    "    final_analysis_results[\"english_toxic_neurons\"] = analyze_differences(\n",
    "        benign_activations_en, toxic_activations_en, layer_names\n",
    "    )\n",
    "    print(\"    Analysis complete. Cleaning toxic activations from memory.\")\n",
    "    del toxic_activations_en\n",
    "else:\n",
    "    print(\"    Failed to get EN activations, skipping comparison.\")\n",
    "    del benign_activations_en\n",
    "    benign_activations_en = None\n",
    "\n",
    "print(\"\\n  --- Comparison 2: Hindi Toxicity (Toxic HI vs Benign HI) ---\")\n",
    "print(\"    Running Benign HI collection...\")\n",
    "benign_file_hi, benign_field_hi = job_file_map[\"benign_HI\"]\n",
    "benign_activations_hi = run_activation_collection(benign_file_hi, benign_field_hi, layer_names)\n",
    "\n",
    "print(\"    Running Toxic HI collection...\")\n",
    "toxic_file_hi, toxic_field_hi = job_file_map[\"toxic_HI\"]\n",
    "toxic_activations_hi = run_activation_collection(toxic_file_hi, toxic_field_hi, layer_names)\n",
    "\n",
    "if benign_activations_hi and toxic_activations_hi:\n",
    "    print(\"    Analyzing (Toxic HI - Benign HI)...\")\n",
    "    final_analysis_results[\"hindi_toxic_neurons\"] = analyze_differences(\n",
    "        benign_activations_hi, toxic_activations_hi, layer_names\n",
    "    )\n",
    "    print(\"    Analysis complete. Cleaning toxic activations from memory.\")\n",
    "    del toxic_activations_hi\n",
    "else:\n",
    "    print(\"    Failed to get HI activations, skipping comparison.\")\n",
    "    del benign_activations_hi\n",
    "    benign_activations_hi = None\n",
    "\n",
    "print(\"\\n  --- Comparison 3 & 4: Language (Benign EN vs Benign HI) ---\")\n",
    "if benign_activations_en and benign_activations_hi:\n",
    "    print(\"    Analyzing (Benign EN - Benign HI)...\")\n",
    "    final_analysis_results[\"english_language_neurons\"] = analyze_differences(\n",
    "        benign_activations_hi, benign_activations_en, layer_names\n",
    "    )\n",
    "    print(\"    Analyzing (Benign HI - Benign EN)...\")\n",
    "    final_analysis_results[\"hindi_language_neurons\"] = analyze_differences(\n",
    "        benign_activations_en, benign_activations_hi, layer_names\n",
    "    )\n",
    "    print(\"    Language analysis complete.\")\n",
    "else:\n",
    "    print(\"    Missing benign EN or HI activations, skipping language comparison.\")\n",
    "\n",
    "print(\"    Cleaning up all remaining activations.\")\n",
    "del benign_activations_en\n",
    "del benign_activations_hi\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n--- 5. All processing complete. Saving final results. ---\")\n",
    "try:\n",
    "    with open(RESULTS_FILE, 'w') as f:\n",
    "        json.dump(final_analysis_results, f, indent=2)\n",
    "    print(f\"Successfully saved 4-way analysis results to '{RESULTS_FILE}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not save final results: {e}\")\n",
    "\n",
    "print(\"\\n--- All Done ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
