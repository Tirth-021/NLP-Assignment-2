{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Preprocessing HASOC CSVs (from .) ---\n",
      "  Processed ./english_2021.csv\n",
      "  Processed ./hindi_2021.csv\n",
      "Preprocessing complete.\n",
      "\n",
      "--- 2. Loading Model and Tokenizer ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8d9a0a49c54873bb18ce788af3eb4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fbd2528d4041a4b748808ea210c570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4421a7080a78482ba9c50bc98ffac651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48353ba9bdb84e468ca8546ce57d5d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba02e2b40cb40d4a079fc1c40c60603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6f1ee1b33a437b9315fec5497b3cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a8a342771a476bb51d54bdbd872c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505d21d24b464803a05d89a03837d6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7793fff89af84052920d43a66741e0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce31545c69484e75828964d8e19ee8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b0de35b65b4916807b4afe2b4c7353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7f34e5b21d47af8e03a8a222a1796f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n",
      "\n",
      "\n",
      "--- 4. Starting LAPE Collection & Analysis Loop ---\n",
      "\n",
      "  --- Comparison 1: Language Specificity (Benign EN vs Benign HI) ---\n",
      "    Running Benign EN collection...\n",
      "    Loaded 1342 prompts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Running Benign HI collection...\n",
      "    Loaded 3161 prompts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Analyzing (Benign EN vs Benign HI)...\n",
      "      Analyzing with LAPE (low entropy)...\n",
      "    Language analysis complete.\n",
      "\n",
      "  --- Comparison 2: English Toxicity Specificity (Toxic EN vs Benign EN) ---\n",
      "    Running Toxic EN collection...\n",
      "    Loaded 2501 prompts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Analyzing (Toxic EN vs Benign EN)...\n",
      "      Analyzing with LAPE (low entropy)...\n",
      "    Analysis complete. Cleaning toxic activations from memory.\n",
      "\n",
      "  --- Comparison 3: Hindi Toxicity Specificity (Toxic HI vs Benign HI) ---\n",
      "    Running Toxic HI collection...\n",
      "    Loaded 1433 prompts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Analyzing (Toxic HI vs Benign HI)...\n",
      "      Analyzing with LAPE (low entropy)...\n",
      "    Analysis complete. Cleaning toxic activations from memory.\n",
      "    Cleaning up all remaining activations.\n",
      "\n",
      "--- 5. All processing complete. Saving final results. ---\n",
      "Successfully saved LAPE analysis results to 'neuron_analysis_results_LAPE.json'.\n",
      "\n",
      "--- All Done ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "HASOC_FOLDER = \".\"\n",
    "TEMP_DATA_FOLDER = \"temp_jsonl_data\"\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "my_token = \"HuggingFaceToken\"\n",
    "batch_size = 64\n",
    "max_length = 400\n",
    "TOP_N_NEURONS = 100\n",
    "RESULTS_FILE = \"neuron_analysis_results_LAPE.json\"\n",
    "ACTIVATION_THRESHOLD = 0.0\n",
    "EPSILON = 1e-9\n",
    "\n",
    "print(f\"--- 1. Preprocessing HASOC CSVs (from {HASOC_FOLDER}) ---\")\n",
    "os.makedirs(TEMP_DATA_FOLDER, exist_ok=True)\n",
    "csv_files_to_process = {\n",
    "    \"EN\": os.path.join(HASOC_FOLDER, \"english_2021.csv\"),\n",
    "    \"HI\": os.path.join(HASOC_FOLDER, \"hindi_2021.csv\")\n",
    "}\n",
    "job_file_map = {}\n",
    "for lang, filepath in csv_files_to_process.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        benign_texts = df[df['task_1'] == 'NOT']['text'].tolist()\n",
    "        benign_outfile = os.path.join(TEMP_DATA_FOLDER, f\"hasoc_{lang}_benign.jsonl\")\n",
    "        job_file_map[f\"benign_{lang}\"] = (benign_outfile, \"BenignCompletion\")\n",
    "        with open(benign_outfile, 'w', encoding='utf-8') as f:\n",
    "            for text in benign_texts: json.dump({\"BenignCompletion\": text}, f); f.write('\\n')\n",
    "        toxic_texts = df[df['task_1'] == 'HOF']['text'].tolist()\n",
    "        toxic_outfile = os.path.join(TEMP_DATA_FOLDER, f\"hasoc_{lang}_toxic.jsonl\")\n",
    "        job_file_map[f\"toxic_{lang}\"] = (toxic_outfile, \"Completion\")\n",
    "        with open(toxic_outfile, 'w', encoding='utf-8') as f:\n",
    "            for text in toxic_texts: json.dump({\"Completion\": text}, f); f.write('\\n')\n",
    "        print(f\"  Processed {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    An error occurred processing {filepath}: {e}\")\n",
    "print(\"Preprocessing complete.\\n\")\n",
    "\n",
    "print(\"--- 2. Loading Model and Tokenizer ---\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=my_token)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"Tokenizer loaded.\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, dtype=torch.bfloat16, device_map=\"auto\", token=my_token\n",
    ")\n",
    "model.eval()\n",
    "print(\"Model and tokenizer loaded successfully.\\n\")\n",
    "\n",
    "def run_activation_collection(input_filename, data_field, layer_names):\n",
    "    all_prompts = []\n",
    "    try:\n",
    "        with open(input_filename, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                all_prompts.append(data[data_field])\n",
    "        print(f\"    Loaded {len(all_prompts)} prompts.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Error loading {input_filename}: {e}\")\n",
    "        return None\n",
    "    activation_storage = {}\n",
    "    hook_handles = []\n",
    "    for layer_name in layer_names:\n",
    "        activation_storage[layer_name] = []\n",
    "    for i, layer in enumerate(model.model.layers):\n",
    "        if i >= len(layer_names): break\n",
    "        handle = layer.mlp.register_forward_hook(\n",
    "            get_hook(activation_storage, layer_names[i])\n",
    "        )\n",
    "        hook_handles.append(handle)\n",
    "    all_collected_activations = {name: [] for name in layer_names}\n",
    "    num_batches = math.ceil(len(all_prompts) / batch_size)\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(all_prompts), batch_size), desc=\"      Processing\", ncols=100, leave=False):\n",
    "            for layer_name in activation_storage:\n",
    "                activation_storage[layer_name].clear()\n",
    "            batch_prompts = all_prompts[i:i+batch_size]\n",
    "            inputs = tokenizer(\n",
    "                batch_prompts, return_tensors=\"pt\", padding=\"max_length\",\n",
    "                truncation=True, max_length=max_length\n",
    "            ).to(\"cuda\")\n",
    "            model(**inputs)\n",
    "            last_token_indices = (inputs[\"attention_mask\"].sum(dim=1) - 1).cpu()\n",
    "            for layer_name, batch_activations_list in activation_storage.items():\n",
    "                full_batch_tensor = batch_activations_list[0]\n",
    "                last_token_activations = full_batch_tensor[\n",
    "                    torch.arange(full_batch_tensor.size(0)),\n",
    "                    last_token_indices\n",
    "                ]\n",
    "                all_collected_activations[layer_name].append(last_token_activations)\n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    final_activations = {}\n",
    "    for layer_name, tensor_list in all_collected_activations.items():\n",
    "        if tensor_list:\n",
    "            final_activations[layer_name] = torch.cat(tensor_list, dim=0)\n",
    "    del all_prompts, all_collected_activations, activation_storage, hook_handles\n",
    "    gc.collect()\n",
    "    return final_activations\n",
    "\n",
    "def get_hook(storage_dict, layer_name):\n",
    "    def hook_fn(module, input, output):\n",
    "        storage_dict[layer_name].append(output.detach().cpu())\n",
    "    return hook_fn\n",
    "\n",
    "def analyze_with_lape(acts_group_1, acts_group_2, layer_names):\n",
    "    print(\"      Analyzing with LAPE (low entropy)...\")\n",
    "    layer_results = {}\n",
    "    for layer_name in layer_names:\n",
    "        tensor_1 = acts_group_1[layer_name]\n",
    "        tensor_2 = acts_group_2[layer_name]\n",
    "        binarized_1 = tensor_1 > ACTIVATION_THRESHOLD\n",
    "        binarized_2 = tensor_2 > ACTIVATION_THRESHOLD\n",
    "        P_1 = binarized_1.float().mean(dim=0)\n",
    "        P_2 = binarized_2.float().mean(dim=0)\n",
    "        total_prob = P_1 + P_2\n",
    "        total_prob[total_prob == 0] = 1.0\n",
    "        p_1 = P_1 / total_prob\n",
    "        p_2 = P_2 / total_prob\n",
    "        log_p_1 = torch.log2(p_1 + EPSILON)\n",
    "        log_p_2 = torch.log2(p_2 + EPSILON)\n",
    "        entropy = - (p_1 * log_p_1 + p_2 * log_p_2)\n",
    "        top_values, top_indices = torch.topk(entropy, TOP_N_NEURONS, largest=False)\n",
    "        top_p1_probs = P_1[top_indices].cpu().float().numpy().tolist()\n",
    "        top_p2_probs = P_2[top_indices].cpu().float().numpy().tolist()\n",
    "        layer_results[layer_name] = {\n",
    "            \"top_neuron_indices\": top_indices.cpu().numpy().tolist(),\n",
    "            \"top_neuron_entropy\": top_values.cpu().float().numpy().tolist(),\n",
    "            \"group_1_fire_prob\": top_p1_probs,\n",
    "            \"group_2_fire_prob\": top_p2_probs\n",
    "        }\n",
    "    return layer_results\n",
    "\n",
    "print(\"\\n--- 4. Starting LAPE Collection & Analysis Loop ---\")\n",
    "layer_names = [f\"model.model.layers.{i}.mlp\" for i in range(len(model.model.layers))]\n",
    "final_analysis_results = {}\n",
    "benign_activations_en = None\n",
    "benign_activations_hi = None\n",
    "\n",
    "print(\"\\n  --- Comparison 1: Language Specificity (Benign EN vs Benign HI) ---\")\n",
    "print(\"    Running Benign EN collection...\")\n",
    "benign_file_en, benign_field_en = job_file_map[\"benign_EN\"]\n",
    "benign_activations_en = run_activation_collection(benign_file_en, benign_field_en, layer_names)\n",
    "print(\"    Running Benign HI collection...\")\n",
    "benign_file_hi, benign_field_hi = job_file_map[\"benign_HI\"]\n",
    "benign_activations_hi = run_activation_collection(benign_file_hi, benign_field_hi, layer_names)\n",
    "if benign_activations_en and benign_activations_hi:\n",
    "    print(\"    Analyzing (Benign EN vs Benign HI)...\")\n",
    "    final_analysis_results[\"language_specific_neurons\"] = analyze_with_lape(\n",
    "        benign_activations_en, benign_activations_hi, layer_names\n",
    "    )\n",
    "    print(\"    Language analysis complete.\")\n",
    "else:\n",
    "    print(\"    Failed to get benign EN or HI activations, skipping language comparison.\")\n",
    "\n",
    "print(\"\\n  --- Comparison 2: English Toxicity Specificity (Toxic EN vs Benign EN) ---\")\n",
    "if benign_activations_en:\n",
    "    print(\"    Running Toxic EN collection...\")\n",
    "    toxic_file_en, toxic_field_en = job_file_map[\"toxic_EN\"]\n",
    "    toxic_activations_en = run_activation_collection(toxic_file_en, toxic_field_en, layer_names)\n",
    "    if toxic_activations_en:\n",
    "        print(\"    Analyzing (Toxic EN vs Benign EN)...\")\n",
    "        final_analysis_results[\"english_toxicity_neurons\"] = analyze_with_lape(\n",
    "            benign_activations_en, toxic_activations_en, layer_names\n",
    "        )\n",
    "        print(\"    Analysis complete. Cleaning toxic activations from memory.\")\n",
    "        del toxic_activations_en\n",
    "    else:\n",
    "        print(\"    Failed to get Toxic EN activations, skipping.\")\n",
    "else:\n",
    "    print(\"    Missing Benign EN activations, skipping English toxicity comparison.\")\n",
    "\n",
    "print(\"\\n  --- Comparison 3: Hindi Toxicity Specificity (Toxic HI vs Benign HI) ---\")\n",
    "if benign_activations_hi:\n",
    "    print(\"    Running Toxic HI collection...\")\n",
    "    toxic_file_hi, toxic_field_hi = job_file_map[\"toxic_HI\"]\n",
    "    toxic_activations_hi = run_activation_collection(toxic_file_hi, toxic_field_hi, layer_names)\n",
    "    if toxic_activations_hi:\n",
    "        print(\"    Analyzing (Toxic HI vs Benign HI)...\")\n",
    "        final_analysis_results[\"hindi_toxicity_neurons\"] = analyze_with_lape(\n",
    "            benign_activations_hi, toxic_activations_hi, layer_names\n",
    "        )\n",
    "        print(\"    Analysis complete. Cleaning toxic activations from memory.\")\n",
    "        del toxic_activations_hi\n",
    "    else:\n",
    "        print(\"    Failed to get Toxic HI activations, skipping.\")\n",
    "else:\n",
    "    print(\"    Missing Benign HI activations, skipping Hindi toxicity comparison.\")\n",
    "\n",
    "print(\"    Cleaning up all remaining activations.\")\n",
    "del benign_activations_en\n",
    "del benign_activations_hi\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n--- 5. All processing complete. Saving final results. ---\")\n",
    "try:\n",
    "    with open(RESULTS_FILE, 'w') as f:\n",
    "        json.dump(final_analysis_results, f, indent=2)\n",
    "    print(f\"Successfully saved LAPE analysis results to '{RESULTS_FILE}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not save final results: {e}\")\n",
    "\n",
    "print(\"\\n--- All Done ---\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
